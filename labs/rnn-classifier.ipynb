{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Classifier\n",
    "\n",
    "This is a copy of the neural network classifier 2. Let's implement an RNN!\n",
    "\n",
    "Changes:\n",
    "- Replace the mean pooling with a simple RNN which we will write from scratch.\n",
    "- To support padding, make [PAD] = token 0, and [UNK] = token 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate\n",
    "\n",
    "import torch.nn.functional as F  # shorthand so we can do F.softmax and other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    tokenizer = Tokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "    train = []\n",
    "    with open(\"SH-TTC/train.tsv\", encoding=\"UTF-8\") as fin:\n",
    "        for line in fin:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            tokens = tokenizer.encode(text).tokens\n",
    "            train.append((label, tokens))\n",
    "\n",
    "    dev = []\n",
    "    with open(\"SH-TTC/dev.tsv\", encoding=\"UTF-8\") as fin:\n",
    "        for line in fin:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            tokens = tokenizer.encode(text).tokens\n",
    "            dev.append((label, tokens))\n",
    "    \n",
    "    return train, dev\n",
    "\n",
    "train_data_raw, dev_data_raw = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens):\n",
    "        self.vocab = [tok for tok, count in Counter(tokens).most_common()]\n",
    "        self.tok2idx = {tok: idx + 2 for idx, tok in enumerate(self.vocab)}\n",
    "        self.tok2idx[0] = \"[PAD]\"\n",
    "        self.tok2idx[1] = \"[UNK]\"\n",
    "        self.idx2tok = {idx: tok for tok, idx in self.tok2idx.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2idx)\n",
    "    \n",
    "    def to_id(self, tok):\n",
    "        return self.tok2idx.get(tok, 0)\n",
    "\n",
    "    def to_tok(self, id):\n",
    "        return self.idx2tok.get(id, \"[UNK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab([word\n",
    "               for y, x in train_data_raw\n",
    "               for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9672"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how to pad a tensor\n",
    "F.pad(torch.Tensor([1,2,3]), (0, 5), value=vocab.to_id(\"[PAD]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShttcDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.data = []\n",
    "        for y, x in tokenized_data:\n",
    "            # LongTensor is for integer ids\n",
    "            x = torch.LongTensor([vocab.to_id(tok) for tok in x])``\n",
    "            x = F.pad(x, (0, 100 - x.size(0)), value=vocab.to_id(\"[PAD]\"))\n",
    "            \n",
    "            if y == \"SH\":\n",
    "                y = torch.Tensor([1, 0])\n",
    "            else:\n",
    "                y = torch.Tensor([0, 1])\n",
    "                \n",
    "            self.data.append((x, y))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ShttcDataset(train_data_raw)\n",
    "dev_data = ShttcDataset(dev_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10381, 1298)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   3,   16,  364, 3376,    5,  173,    2,  284,    2,   17, 1255,    2,\n",
       "           30,   26,  561,    2,    5, 2399, 2975,   12, 5504,   13,    5, 1074,\n",
       "          270,   28,   36, 1820,    2,   12,   17,   78,   32,  225,  102,   20,\n",
       "         1485,   29,  324,   59,    6,    4,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model!\n",
    "\n",
    "We want the following structure:\n",
    "\n",
    "Tokens -> Embed -> RNN -> Hidden -> Output\n",
    "\n",
    "After padding, the input tokens are all the same length. After we get the embeddings, we will run them one by one through the RNN, which will automatically update its hidden state.\n",
    "\n",
    "Let's break down each component of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[0][0]\n",
    "y = train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somewhat following https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = torch.nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initial_hidden(self):\n",
    "        return torch.zeros(self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(len(vocab), 50)   # input = |V|, output = 50 (emb size)\n",
    "rnn = SimpleRNN(50, 50)\n",
    "linear1 = torch.nn.Linear(50, 2)  # emb size -> output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8952, -1.0249,  0.4444,  ..., -0.1904,  0.6466,  0.4470],\n",
       "        [-0.5850, -0.9442, -1.0992,  ...,  1.1571,  0.8177, -1.0776],\n",
       "        [ 0.3221,  0.1908,  0.8119,  ..., -0.8874, -0.5927, -1.1309],\n",
       "        ...,\n",
       "        [-0.0978,  0.7601,  0.1314,  ..., -0.1516,  0.2974,  0.0963],\n",
       "        [-0.0978,  0.7601,  0.1314,  ..., -0.1516,  0.2974,  0.0963],\n",
       "        [-0.0978,  0.7601,  0.1314,  ..., -0.1516,  0.2974,  0.0963]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = emb(x)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape  # (n tokens, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = rnn(e, rnn.initial_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1062, -0.0826,  0.1073,  ...,  0.3799,  0.3248, -0.0334],\n",
       "        [-0.3336,  0.3620,  0.1479,  ...,  0.6544, -0.2964,  0.3555],\n",
       "        [ 0.1304, -0.2753,  0.2213,  ...,  0.5530,  0.3009,  0.1784],\n",
       "        ...,\n",
       "        [-0.3503, -0.0023, -0.0591,  ...,  0.4398, -0.0648,  0.4496],\n",
       "        [-0.3503, -0.0023, -0.0591,  ...,  0.4398, -0.0648,  0.4496],\n",
       "        [-0.3503, -0.0023, -0.0591,  ...,  0.4398, -0.0648,  0.4496]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape  # (n tokens, 50), one vector for each timestep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0352, -0.4843, -0.0590,  ...,  0.4745,  0.2591,  0.4735],\n",
       "        [-0.8966, -0.0250,  0.3315,  ...,  0.2996, -0.3051, -0.3490],\n",
       "        [ 0.5499,  0.0852,  0.6340,  ...,  0.0252,  0.8690, -0.2278],\n",
       "        ...,\n",
       "        [-0.2615,  0.5056,  0.2398,  ...,  0.6183, -0.1203,  0.5294],\n",
       "        [-0.2615,  0.5056,  0.2398,  ...,  0.6183, -0.1203,  0.5294],\n",
       "        [-0.2615,  0.5056,  0.2398,  ...,  0.6183, -0.1203,  0.5294]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape  # (n tokens, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each timestep\n",
    "hidden = rnn.initial_hidden()\n",
    "for i in range(len(e)):\n",
    "    output, hidden = rnn(e[i], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3279,  0.6016,  0.1281, -0.0426, -0.6983,  0.4003, -0.5681, -0.6937,\n",
       "         0.4413,  0.2617,  0.0911, -0.4249,  0.1860,  0.1093, -0.4143,  0.2682,\n",
       "        -0.0604, -0.3182, -0.5093, -0.3150,  0.4222,  0.5239,  0.3401,  0.4358,\n",
       "        -0.2037,  0.2823, -0.1884, -0.6619,  0.1288, -0.5169,  0.3293, -0.0506,\n",
       "        -0.1999,  0.4386,  0.4022,  0.6700,  0.3085, -0.3685,  0.2775, -0.8203,\n",
       "        -0.2625, -0.6087,  0.2349, -0.2632, -0.7485, -0.2940, -0.1349,  0.6692,\n",
       "        -0.4595,  0.6520], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden  # now has encoded the entire sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0323,  0.0198], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = linear1(hidden)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7195, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(yhat, y)  # automatically does the softmax and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, voc_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(voc_size, emb_size)\n",
    "        self.rnn = SimpleRNN(emb_size, hidden_size)\n",
    "        self.linear = torch.nn.Linear(emb_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x)\n",
    "        \n",
    "        hidden = self.rnn.initial_hidden()\n",
    "        for i in range(len(e)):\n",
    "            _out, hidden = self.rnn(e[i], hidden)\n",
    "\n",
    "        y = self.linear(hidden)\n",
    "        return y  # don't need sigmoid because cross_entropy computes sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(len(vocab), 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight \t 483600\n",
      "rnn.i2h.weight \t 2500\n",
      "rnn.i2h.bias \t 50\n",
      "rnn.h2h.weight \t 2500\n",
      "rnn.h2h.bias \t 50\n",
      "rnn.h2o.weight \t 2500\n",
      "rnn.h2o.bias \t 50\n",
      "linear.weight \t 100\n",
      "linear.bias \t 2\n",
      "Total Trainable Params: 491352\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        print(name, \"\\t\", params)\n",
    "        total_params += params\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1.1002e-01, -3.7635e-04, -8.6351e-01,  ..., -3.5153e-02,\n",
      "          2.9881e-01,  3.6698e-01],\n",
      "        [ 2.7310e-02,  3.2312e-01,  9.3862e-02,  ...,  3.2303e-01,\n",
      "          1.1172e-01,  2.0826e-01],\n",
      "        [ 1.4793e-01,  1.9386e-01, -2.6678e-01,  ..., -2.4321e-01,\n",
      "         -2.1960e-02, -6.3066e-01],\n",
      "        ...,\n",
      "        [-2.1318e-01,  1.0358e-01,  2.8842e-01,  ..., -1.5286e-01,\n",
      "          4.8213e-02, -7.1092e-02],\n",
      "        [-2.1318e-01,  1.0358e-01,  2.8842e-01,  ..., -1.5286e-01,\n",
      "          4.8213e-02, -7.1092e-02],\n",
      "        [-2.1318e-01,  1.0358e-01,  2.8842e-01,  ..., -1.5286e-01,\n",
      "          4.8213e-02, -7.1092e-02]]), tensor([[-0.3097, -0.8766, -0.0166,  ..., -0.7016, -0.3213,  0.2376],\n",
      "        [-0.0409, -0.2567, -0.3584,  ...,  0.4818, -0.1989,  0.1717],\n",
      "        [-0.8485,  0.8749, -0.1641,  ..., -0.1630, -0.8509,  0.1757],\n",
      "        ...,\n",
      "        [-0.4566,  0.2630, -0.1004,  ...,  0.1121,  0.0827,  0.1520],\n",
      "        [-0.4566,  0.2630, -0.1004,  ...,  0.1121,  0.0827,  0.1520],\n",
      "        [-0.4566,  0.2630, -0.1004,  ...,  0.1121,  0.0827,  0.1520]]))\n",
      "tensor([-0.2547,  0.0729])\n"
     ]
    }
   ],
   "source": [
    "# get prediction for a single data point\n",
    "# no_grad means we don't need to calculate gradients\n",
    "# (do this when testing the model)\n",
    "with torch.no_grad():\n",
    "    x = train_data[0][0]\n",
    "    # x = torch.LongTensor([x.tolist()])\n",
    "    print(model.rnn(model.emb(x), model.rnn.initial_hidden()))\n",
    "    print(model(x))\n",
    "\n",
    "# Note: once you batch and change your torch.mean line,\n",
    "# your model will not accept a single datapoint anymore,\n",
    "# so you need to uncomment the above line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the training\n",
    "loss_func = F.cross_entropy  # same as torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6129448a6a344f9fa250b4566aca81ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1114f618df94ebbbe8457da33797fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6897)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bd04c8f8c34145b31763b46f9216c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6914)\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f16c3719b0b484092026836db55d9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaf29579d4c476fb58becda3c2f71b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6904)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0062fe4d8a074871b5d414fbb7b47450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6935)\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728ea255ef71426d954c0ff70fb152c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c518fce085d4db9910227bac4fa92b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6903)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12251d6b150f4182a4b1637170799be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6955)\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613372f5c292449e8884dc38b8f00e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6139f6523544ccaf90ffc38086bc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6893)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a0131210314777b552f74adff0d6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6994)\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978a229d5bca4620b584931f6eb91e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bf936fae0d412485d4e3ca71ed8913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6978)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5710aa30cf489c879be48b50265911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.7023)\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57406e297e2b4eceba63b7d6b473f00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a5b358610c492793f4aa2bd2764322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6954)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddef618e17d84932a02de2a61206f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.7018)\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202bb5e626346e19d7d8b7e9aeae93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b53bb1877f244ecb36b85e5fed86b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6878)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4f16e44ea842ae9e684da53690be61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6937)\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078d1daf6278488cab97532619d12516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1274256ce89499ca047bde842f4b986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6882)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73313251eb7f4676978d7e7e073d6a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6971)\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a2a9adfe94758a0179bf4cfbb08cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1ace93cc264c3c955ce1985ef49d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6862)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29097512bd694eb68f8866d678461b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6939)\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d13b13cbd343639c188eea556ccf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6921b17df9ee433aacd2c3f50c893d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6868)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091a19cf7de24493a5bb7bad84bc2808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss: tensor(0.6956)\n"
     ]
    }
   ],
   "source": [
    "# train!\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch\", epoch)\n",
    "\n",
    "    random.shuffle(train_data.data)  # TODO: not really good style, remove this when using dataloader\n",
    "    \n",
    "    for x, y in tqdm(train_data):\n",
    "        model.zero_grad()  # do this before running\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        loss.backward()  # calculate gradients\n",
    "        optimizer.step()  # updates thetas\n",
    "\n",
    "    # after each epoch, check how we're doing\n",
    "    # compute avg loss over train and dev sets\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x, y in tqdm(train_data):\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_loss += loss\n",
    "        print(\"train loss:\", total_loss / len(train_data))\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in tqdm(dev_data):\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_loss += loss\n",
    "        print(\"dev loss:\", total_loss / len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_dev_data():\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dev_data:\n",
    "            pred = model(x)  # pred is something like [0.6, 0.4]\n",
    "            # TODO: when using batched inputs, your output will also be batched\n",
    "            # so you need to split them before appending to preds\n",
    "            preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "def sample_predictions(preds):\n",
    "    for _ in range(5):\n",
    "        idx = random.randint(0, len(dev_data))\n",
    "        \n",
    "        # argmax gives the index with the highest value\n",
    "        pred_label = \"SH\" if torch.argmax(preds[idx]) == 0 else \"TTC\"\n",
    "\n",
    "        print(\"Input:\", \" \".join(dev_data_raw[idx][1]))\n",
    "        print(\"Gold: \", dev_data_raw[idx][0])\n",
    "\n",
    "        # preds are not normalized, so for better viewing, run it through softmax\n",
    "        print(\"Pred: \", pred_label, F.softmax(preds[idx], dim=0)) \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = run_model_on_dev_data()\n",
    "sample_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate functions require numeric data, so convert labels to 0 and 1\n",
    "refs = []\n",
    "for label, text in dev_data_raw:\n",
    "    if label == \"SH\":\n",
    "        refs.append(0)\n",
    "    else:\n",
    "        refs.append(1)\n",
    "\n",
    "preds_binary = []\n",
    "for pred in preds:\n",
    "    preds_binary.append(torch.argmax(pred))\n",
    "\n",
    "print(precision.compute(references=refs, predictions=preds_binary))\n",
    "print(recall.compute(references=refs, predictions=preds_binary))\n",
    "print(accuracy.compute(references=refs, predictions=preds_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks\n",
    "\n",
    "- Use a DataLoader, which supports automatic batching and shuffling\n",
    "    - You will need to pad your inputs to a constant length using `torch.nn.functional.pad` so that the DataLoader can batch properly. Use `pad` to add zeros to the right of the sequence so the length is 100. (You did not need to do this in nn-classifier1 because the input lengths were already equal)\n",
    "    - Alternatively, use `torch.nn.utils.rnn.pack_padded_sequence`\n",
    "    - Pack the sequence using `pack_padded_sequence`, run it through your RNN, then use `pad_packed_sequence`.\n",
    "    - See [this link](https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html) for an example.\n",
    "    - RNNs in PyTorch have the batch dim 1. To make it 0 (recommended), set batch_first=True\n",
    "- Use torch.nn.RNN/LSTM/GRU instead of writing your own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
