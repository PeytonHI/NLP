{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier 2\n",
    "\n",
    "This is a copy of the neural network classifier 1 with some minor changes, so if you haven't gone through that notebook, then do that first!\n",
    "\n",
    "Changes:\n",
    "- DataSet class to handle the data\n",
    "- Embedding layer will compute a vector representation of each token\n",
    "- Instead of a counts vector of length $V$, the input is now a sequence of token ids\n",
    "- These embeddings will get averaged into a single vector, which will be the input to the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate\n",
    "\n",
    "import torch.nn.functional as F  # shorthand so we can do F.softmax and other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SH', ['[CLS]', '‘', 'What', 'have', 'I', 'to', 'do', 'with', 'sun', '##dial', '##s', 'and', 'papers', '?', '[SEP]']), ('SH', ['[CLS]', 'Let', 'me', 'have', 'the', 'date', 'of', 'the', 'reception', 'by', 'your', 'uncle', 'of', 'the', 'letter', ',', 'and', 'the', 'date', 'of', 'his', 'supposed', 'suicide', '.', '”', '[SEP]']), ('SH', ['[CLS]', '“', 'That', 'is', 'a', 'detail', 'which', 'I', 'shall', 'speed', '##ily', 'supply', '.', '”', '[SEP]']), ('SH', ['[CLS]', 'And', 'on', 'the', 'morning', 'of', 'the', 'wedding', '?', '”', '“', 'She', 'was', 'as', 'bright', 'as', 'possible', '—', 'at', 'least', 'until', 'after', 'the', 'ceremony', '.', '”', '[SEP]']), ('SH', ['[CLS]', '“', 'I', 'am', 'sorry', 'to', 'knock', 'you', 'up', 'so', 'early', ',', '[', 'N', '##AM', '##E', ']', ',', '”', 'said', 'he', ',', '“', 'but', 'I', 'have', 'had', 'a', 'very', 'serious', 'accident', 'during', 'the', 'night', '.', '[SEP]']), ('SH', ['[CLS]', 'I', 'shall', 'look', 'forward', 'to', 'seeing', 'you', 'again', 'this', 'afternoon', '.', '”', '[SEP]']), ('SH', ['[CLS]', 'It', 'is', 'probable', '.', '[SEP]']), ('SH', ['[CLS]', '“', 'Well', ',', 'you', 'can', 'ask', 'the', '[', 'N', '##AM', '##E', ']', 'of', '[', 'N', '##AM', '##E', ']', ',', 'for', 'all', 'I', 'care', '.', '[SEP]']), ('SH', ['[CLS]', 'Present', '##ly', 'she', 'emerged', 'from', 'the', 'room', 'again', ',', 'and', 'in', 'the', 'light', 'of', 'the', 'passage', '-', 'lamp', 'your', 'son', 'saw', 'that', 'she', 'carried', 'the', 'precious', 'co', '##rone', '##t', 'in', 'her', 'hands', '.', '[SEP]']), ('SH', ['[CLS]', 'I', 'shall', 'be', 'happy', 'to', 'give', 'you', 'an', 'opinion', 'upon', 'the', 'subject', 'in', 'the', 'course', 'of', 'a', 'day', 'or', 'two', '.', '[SEP]']), ('SH', ['[CLS]', 'It', 'was', 'obvious', 'to', 'me', 'that', 'my', 'companion', '’', 's', 'mind', 'was', 'now', 'made', 'up', 'about', 'the', 'case', ',', 'although', 'what', 'his', 'conclusions', 'were', 'was', 'more', 'than', 'I', 'could', 'even', 'dim', '##ly', 'imagine', '.', '[SEP]']), ('SH', ['[CLS]', 'Again', 'a', 'startled', 'look', 'came', 'over', 'the', 'somewhat', 'v', '##ac', '##uous', 'face', 'of', '[', 'N', '##AM', '##E', ']', '[', 'N', '##AM', '##E', ']', '[', 'N', '##AM', '##E', ']', '.', '[SEP]']), ('SH', ['[CLS]', '“', 'Have', 'you', 'ever', 'observed', 'that', 'his', 'ears', 'are', 'pierced', 'for', 'ear', '##rings', '?', '”', '[SEP]']), ('SH', ['[CLS]', 'Have', 'you', 'followed', 'me', 'so', 'far', '?', '”', '[SEP]']), ('SH', ['[CLS]', 'The', 'central', 'portion', 'was', 'in', 'little', 'better', 'repair', ',', 'but', 'the', 'right', '-', 'hand', 'block', 'was', 'comparatively', 'modern', ',', 'and', 'the', 'blind', '##s', 'in', 'the', 'windows', ',', 'with', 'the', 'blue', 'smoke', 'curling', 'up', 'from', 'the', 'chimney', '##s', ',', 'showed', 'that', 'this', 'was', 'where', 'the', 'family', 'resided', '.', '[SEP]']), ('SH', ['[CLS]', 'He', 'slipped', 'his', 'key', 'into', 'the', 'lock', ',', 'and', 'we', 'all', 'very', 'quietly', 'entered', 'the', 'cell', '.', '[SEP]']), ('SH', ['[CLS]', '“', '‘', 'Oh', ',', 'any', 'old', 'key', 'will', 'fit', 'that', 'bureau', '.', '[SEP]']), ('SH', ['[CLS]', '“', 'One', 'moment', ',', '”', '[', 'N', '##AM', '##E', ']', 'inter', '##posed', ',', '“', 'your', 'statement', 'is', ',', 'I', 'fore', '##see', ',', 'one', 'of', 'the', 'most', 'remarkable', 'to', 'which', 'I', 'have', 'ever', 'listened', '.', '[SEP]']), ('SH', ['[CLS]', 'By', 'profession', 'I', 'am', 'a', 'hydraulic', 'engineer', ',', 'and', 'I', 'have', 'had', 'considerable', 'experience', 'of', 'my', 'work', 'during', 'the', 'seven', 'years', 'that', 'I', 'was', 'apprentice', '##d', 'to', '[', 'N', '##AM', '##E', ']', '&', '[', 'N', '##AM', '##E', ']', ',', 'the', 'well', '-', 'known', 'firm', ',', 'of', '[', 'N', '##AM', '##E', ']', '.', '[SEP]']), ('SH', ['[CLS]', '“', 'And', 'what', 'did', 'you', 'see', '?', '”', '[SEP]'])]\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    tokenizer = Tokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "    train = []\n",
    "    with open(\"SH-TTC/train.tsv\", encoding=\"UTF-8\") as fin:\n",
    "        for line in fin:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            tokens = tokenizer.encode(text).tokens\n",
    "            train.append((label, tokens))\n",
    "\n",
    "    dev = []\n",
    "    with open(\"SH-TTC/dev.tsv\", encoding=\"UTF-8\") as fin:\n",
    "        for line in fin:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            tokens = tokenizer.encode(text).tokens\n",
    "            dev.append((label, tokens))\n",
    "    \n",
    "    return train, dev\n",
    "\n",
    "train_data_raw, dev_data_raw = read_data()\n",
    "print(dev_data_raw[0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens):\n",
    "        self.vocab = [tok for tok, count in Counter(tokens).most_common()]\n",
    "        self.tok2idx = {tok: idx + 1 for idx, tok in enumerate(self.vocab)}\n",
    "        self.tok2idx[0] = \"[UNK]\"\n",
    "        self.idx2tok = {idx: tok for tok, idx in self.tok2idx.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2idx)\n",
    "    \n",
    "    def to_id(self, tok):\n",
    "        return self.tok2idx.get(tok, 0)\n",
    "\n",
    "    def to_tok(self, id):\n",
    "        return self.idx2tok.get(id, \"[UNK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab([word\n",
    "               for y, x in train_data_raw\n",
    "               for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9671"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShttcDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.data = []\n",
    "        for y, x in tokenized_data:\n",
    "            # LongTensor is for integer ids\n",
    "            x = torch.LongTensor([vocab.to_id(tok) for tok in x])\n",
    "            \n",
    "            if y == \"SH\":\n",
    "                y = torch.Tensor([1, 0])\n",
    "            else:\n",
    "                y = torch.Tensor([0, 1])\n",
    "                \n",
    "            self.data.append((x, y))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ShttcDataset(train_data_raw)\n",
    "dev_data = ShttcDataset(dev_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10381, 1298)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   2,   15,  363, 3375,    4,  172,    1,  283,    1,   16, 1254,    1,\n",
       "           29,   25,  560,    1,    4, 2398, 2974,   11, 5503,   12,    4, 1073,\n",
       "          269,   27,   35, 1819,    1,   11,   16,   77,   31,  224,  101,   19,\n",
       "         1484,   28,  323,   58,    5,    3]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model!\n",
    "\n",
    "We want the following structure:\n",
    "\n",
    "Tokens -> Embed -> Hidden -> Output\n",
    "\n",
    "The problem is that the input can be variable length. So after we get the embeddings, we will use mean pooling, so that the input to the hidden layer has a fixed size.\n",
    "\n",
    "Let's break down each component of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[0][0]\n",
    "y = train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(len(vocab), 50)   # input = |V|, output = 50 (emb size)\n",
    "linear1 = torch.nn.Linear(50, 50)  # emb size -> hidden size\n",
    "linear2 = torch.nn.Linear(50, 2)  # hidden size -> output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8790,  0.0843, -0.9360,  ...,  1.3626,  0.1041, -0.1704],\n",
       "        [ 0.7654,  0.1776, -0.9183,  ..., -1.0696,  0.1173, -1.4512],\n",
       "        [-0.3904,  0.3017,  1.1361,  ..., -0.8859, -0.6963,  0.7852],\n",
       "        ...,\n",
       "        [ 0.5199,  0.0571,  1.4610,  ...,  0.7754,  1.2393,  0.4563],\n",
       "        [-1.1866,  0.6333,  0.8945,  ..., -0.5109, -1.5369, -0.1395],\n",
       "        [-1.2452, -2.0386,  3.0467,  ..., -0.6121, -1.0770, -1.3523]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = emb(x)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 50])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape  # (n tokens, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_mean = torch.mean(e, dim=0)  # dim=0 will do element-wise mean, so the result has shape (50)\n",
    "e_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0538,  0.0361, -0.1072, -0.3866, -0.0068,  0.2832,  0.0442,  0.3247,\n",
       "         0.0450,  0.1217, -0.0498,  0.1295,  0.1963, -0.2979, -0.0727, -0.0354,\n",
       "         0.0273, -0.0094,  0.1431, -0.0670, -0.0644, -0.0363,  0.1676, -0.3237,\n",
       "         0.2153,  0.1263, -0.0789,  0.2627, -0.1378,  0.0343,  0.0732,  0.1453,\n",
       "        -0.1379,  0.1150,  0.2551,  0.4546,  0.0691, -0.0193, -0.2975, -0.0842,\n",
       "         0.1738, -0.1802, -0.2405,  0.0381, -0.1912, -0.1590, -0.0357, -0.0809,\n",
       "         0.2163,  0.0191], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1862, 0.0869, 0.0885, 0.0000, 0.0000, 0.0000, 0.2752, 0.0000, 0.0000,\n",
       "        0.0000, 0.1284, 0.0038, 0.0000, 0.0000, 0.0613, 0.0000, 0.0000, 0.0477,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.1256, 0.0000, 0.0000, 0.0000, 0.2537,\n",
       "        0.0000, 0.1305, 0.0000, 0.0000, 0.0000, 0.1843, 0.0000, 0.0129, 0.0000,\n",
       "        0.0661, 0.0000, 0.0000, 0.0596, 0.0000, 0.0000, 0.0777, 0.0000, 0.0239,\n",
       "        0.0992, 0.0000, 0.0000, 0.0000, 0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = linear1(e_mean)\n",
    "h1 = F.relu(h1)\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1439, -0.1760], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = linear2(h1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8658, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(y, torch.Tensor([0, 1]))  # automatically does the softmax and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier2(torch.nn.Module):\n",
    "    def __init__(self, voc_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(voc_size, emb_size)\n",
    "        self.linear1 = torch.nn.Linear(emb_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x)  # (n tokens, 50)\n",
    "        e_mean = torch.mean(e, dim=0)  # (50)\n",
    "        h = self.linear1(e_mean)\n",
    "        h = F.relu(h)\n",
    "        y = self.linear2(h)\n",
    "        return y  # don't need sigmoid because cross_entropy computes sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNClassifier2(len(vocab), 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight \t 483550\n",
      "linear1.weight \t 2500\n",
      "linear1.bias \t 50\n",
      "linear2.weight \t 100\n",
      "linear2.bias \t 2\n",
      "Total Trainable Params: 486202\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        print(name, \"\\t\", params)\n",
    "        total_params += params\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0601, -0.0164])\n"
     ]
    }
   ],
   "source": [
    "# get prediction for a single data point\n",
    "# no_grad means we don't need to calculate gradients\n",
    "# (do this when testing the model)\n",
    "with torch.no_grad():\n",
    "    x = train_data[0][0]\n",
    "    print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the training\n",
    "loss_func = F.cross_entropy  # same as torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train loss: tensor(0.4263)\n",
      "dev loss: tensor(0.4776)\n",
      "Epoch 1\n",
      "train loss: tensor(0.3174)\n",
      "dev loss: tensor(0.4287)\n",
      "Epoch 2\n",
      "train loss: tensor(0.2542)\n",
      "dev loss: tensor(0.4432)\n",
      "Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(pred, y)\n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# calculate gradients\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# updates thetas\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# after each epoch, check how we're doing\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# compute avg loss over train and dev sets\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peyto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    376\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train!\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch\", epoch)\n",
    "\n",
    "    random.shuffle(train_data.data)  # not really good style, remove this when using dataloader\n",
    "    \n",
    "    for x, y in train_data:\n",
    "        model.zero_grad()  # do this before running\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        loss.backward()  # calculate gradients\n",
    "        optimizer.step()  # updates thetas\n",
    "\n",
    "    # after each epoch, check how we're doing\n",
    "    # compute avg loss over train and dev sets\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x, y in train_data:\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_loss += loss\n",
    "        print(\"train loss:\", total_loss / len(train_data))\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in dev_data:\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_loss += loss\n",
    "        print(\"dev loss:\", total_loss / len(dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_dev_data():\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dev_data:\n",
    "            pred = model(x)  # pred is something like [0.6, 0.4]\n",
    "            preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "def sample_predictions(preds):\n",
    "    for _ in range(5):\n",
    "        idx = random.randint(0, len(dev_data))\n",
    "        \n",
    "        # argmax gives the index with the highest value\n",
    "        pred_label = \"SH\" if torch.argmax(preds[idx]) == 0 else \"TTC\"\n",
    "\n",
    "        print(\"Input:\", \" \".join(dev_data_raw[idx][1]))\n",
    "        print(\"Gold: \", dev_data_raw[idx][0])\n",
    "\n",
    "        # preds are not normalized, so for better viewing, run it through softmax\n",
    "        print(\"Pred: \", pred_label, F.softmax(preds[idx], dim=0)) \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [CLS] I have watched the fellow more than once before ever I thought of making his professional acquaintance , and I have been surprised at the harvest which he has re ##ap ##ed in a short time . [SEP]\n",
      "Gold:  SH\n",
      "Pred:  SH tensor([0.9988, 0.0012])\n",
      "\n",
      "Input: [CLS] The butcher and the pork ##man painted up , only the lean ##est s ##c ##rag ##s of meat ; the b ##aker , the coarse ##st of me ##ag ##re lo ##aves . [SEP]\n",
      "Gold:  TTC\n",
      "Pred:  TTC tensor([2.9366e-05, 9.9997e-01])\n",
      "\n",
      "Input: [CLS] “ Have you ever observed that his ears are pierced for ear ##rings ? ” [SEP]\n",
      "Gold:  SH\n",
      "Pred:  TTC tensor([0.1602, 0.8398])\n",
      "\n",
      "Input: [CLS] “ Yes , at the mines . ” [SEP]\n",
      "Gold:  SH\n",
      "Pred:  SH tensor([0.6725, 0.3275])\n",
      "\n",
      "Input: [CLS] I lounge ##d up the side aisle like any other idle ##r who has dropped into a church . [SEP]\n",
      "Gold:  SH\n",
      "Pred:  SH tensor([0.9500, 0.0500])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = run_model_on_dev_data()\n",
    "sample_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 7.55k/7.55k [00:00<00:00, 3.77MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<?, ?B/s]\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.7723684210526316}\n",
      "{'recall': 0.8670605612998523}\n",
      "{'accuracy': 0.7973805855161787}\n"
     ]
    }
   ],
   "source": [
    "# evaluate functions require numeric data, so convert labels to 0 and 1\n",
    "refs = []\n",
    "for label, text in dev_data_raw:\n",
    "    if label == \"SH\":\n",
    "        refs.append(0)\n",
    "    else:\n",
    "        refs.append(1)\n",
    "\n",
    "preds_binary = []\n",
    "for pred in preds:\n",
    "    preds_binary.append(torch.argmax(pred))\n",
    "\n",
    "print(precision.compute(references=refs, predictions=preds_binary))\n",
    "print(recall.compute(references=refs, predictions=preds_binary))\n",
    "print(accuracy.compute(references=refs, predictions=preds_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks\n",
    "\n",
    "- Use a dataloader, which supports automatic batching and shuffling\n",
    "- Make tweaks to your model and compare their performance. This is called hyperparameter tuning, and it is really more of an art than a science. Some things you can try:\n",
    "    - Change the batch size\n",
    "        - larger = faster to train, but model may be less generalizable\n",
    "    - Change the embedding size and hidden layer size\n",
    "        - larger = slower to train, but usually better results. Try to see how small you can get it without severely degrading results!\n",
    "    - Try different activation functions (full list at https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)\n",
    "        - Most popular now is ReLU and its variants. There is no one best activation function for every task, so people usually start with ReLU since it is simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
